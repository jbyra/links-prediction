{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def read_input_graph(filename, verticles):\n",
    "    \n",
    "    vec_map = defaultdict(int)\n",
    "    i =0\n",
    "    for x in verticles:\n",
    "        vec_map[x] = i\n",
    "        i +=1\n",
    "        \n",
    "    neighbours = {}\n",
    "    for line in open(filename):\n",
    "        line = line.replace('[', ' ').replace(']', ' ')\n",
    "        verticles = line.rstrip().split(' ')\n",
    "        if len(verticles) >0:\n",
    "            neighbours[vec_map[int(verticles[0])]] = list(map( lambda x : vec_map[int(x)], verticles[1::2]))\n",
    "    \n",
    "    return neighbours, vec_map\n",
    "\n",
    "def read_output_data(filename):\n",
    "    output = np.genfromtxt(filename, delimiter=' ')\n",
    "    ids_output = output[..., 0].astype(np.intc)\n",
    "    vectors = output[..., 1:]\n",
    "    return vectors, ids_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_X_y(vectors, neighbours, data_len=1000):\n",
    "    \"\"\"\n",
    "        Returns \n",
    "        X: fabs(a - b)\n",
    "        y: label 1 -> connected \n",
    "    \"\"\"\n",
    "    rand_idxs  = np.arange(vectors.shape[0])\n",
    "    np.random.shuffle(rand_idxs)\n",
    "\n",
    "    i = 0\n",
    "    j=0\n",
    "    b_true = []\n",
    "    while len(b_true) < data_len//2 and i<rand_idxs.shape[0]:\n",
    "        n = neighbours.get(rand_idxs[i])\n",
    "        if n:\n",
    "            b_true.append(np.random.choice(n, 1))\n",
    "        i+=1\n",
    "\n",
    "    b_true = np.array(b_true)\n",
    "    data_len = min(data_len//2, b_true.shape[0])\n",
    "    \n",
    "    np.random.shuffle(rand_idxs)\n",
    "    b_false = rand_idxs[:data_len]\n",
    "\n",
    "    b = np.concatenate((b_true.reshape(b_true.shape[0], 1), b_false.reshape(b_false.shape[0], 1)), axis=0)\n",
    "\n",
    "    y = np.concatenate((np.ones(b_true.shape[0]), np.zeros(b_false.shape[0])), axis=0).astype(np.intc)\n",
    "\n",
    "    a = rand_idxs[:y.shape[0]]\n",
    "    fabs_x = np.fabs(vectors[a]-vectors[b].reshape(y.shape[0], 48))    \n",
    "    return fabs_x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "def score_regression(X, y, X_test, y_test):\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    clf = lr.fit(X, y)\n",
    "\n",
    "    p = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, p)\n",
    "    accuracy = accuracy_score(y_test, p)\n",
    "    recall = recall_score(y_test, p)\n",
    "    prec = precision_score(y_test, p)\n",
    "    print(\"score:\")\n",
    "    print(\"f1: {}\".format(f1))\n",
    "    print(\"accuracy: {}\".format(accuracy))\n",
    "    print(\"recall: {}\".format(recall))\n",
    "    print(\"prec: {}\".format(prec))\n",
    "    return f1, accuracy, recall, prec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score:\n",
      "f1: 0.5806451612903227\n",
      "accuracy: 0.6130952380952381\n",
      "recall: 0.5357142857142857\n",
      "prec: 0.6338028169014085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5806451612903227,\n",
       " 0.6130952380952381,\n",
       " 0.5357142857142857,\n",
       " 0.6338028169014085)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectors, ids_temp = read_output_data('dblp-mini-output/dblp-mini-output/1.out')\n",
    "n, _ = read_input_graph('2017.in', ids_temp)\n",
    "\n",
    "X, y = get_X_y(vectors, n)\n",
    "\n",
    "vectors_t, ids_t = read_output_data('dblp-mini-output/dblp-mini-output/2.out')\n",
    "neighbours_t, _ = read_input_graph('2018.in', ids_t)\n",
    "\n",
    "X_test, y_test = get_X_y(vectors_t, neighbours_t)\n",
    "\n",
    "score_regression(X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
